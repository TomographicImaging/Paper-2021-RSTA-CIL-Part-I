{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "superb-imaging",
   "metadata": {},
   "source": [
    "# PET data case\n",
    "\n",
    "Tested with CIL 21.1.0 and SIRF 3.0.0\n",
    "\n",
    "The data is a real dataset of a phantom acquisition at UCL on a Siemens mMR. The phantom is the NEMA phantom (essentially a torso-shaped perspex box, with some spherical inserts).  The data is freely available on [Zenodo](https://zenodo.org/record/1304454#.YJU7xbVKg10).\n",
    "\n",
    "The data must be downloaded and put in a the directory pointed by `data_path`.\n",
    "\n",
    "Parts of this notebook are taken from the SIRF exercise [reconstruct_measured_data ](https://github.com/SyneRBI/SIRF-Exercises/blob/master/notebooks/PET/reconstruct_measured_data.ipynb) from CCP SyneRBI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sirf.STIR as pet\n",
    "from sirf.config import SIRF_HAS_Parallelproj\n",
    "\n",
    "from cil.utilities.display import show2D\n",
    "from cil.optimisation.algorithms import PDHG, SPDHG\n",
    "from cil.optimisation.functions import KullbackLeibler\n",
    "from cil.plugins.ccpi_regularisation.functions import FGP_TV\n",
    "from ccpi.filters import regularisers\n",
    "\n",
    "# change data_path to point to the directory where the data has been downloaded and unzipped\n",
    "data_path = os.path.abspath('/home/ofn77899/devel/buildVM/INSTALL/share/SIRF-3.0/data/examples/PET/mMR_newserver')\n",
    "os.chdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file names\n",
    "list_file = '20170809_NEMA_60min_UCL.l.hdr'\n",
    "norm_file = 'norm.n.hdr'\n",
    "attn_file = 'mu_map.hv'\n",
    "# output filename prefixes\n",
    "sino_file = 'sino'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-pierre",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redirect STIR messages to some files\n",
    "# you can check these if things go wrong\n",
    "msg_red = pet.MessageRedirector('info.txt', 'warn.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_acq_data = pet.AcquisitionData('Siemens_mMR', span=11, max_ring_diff=15, view_mash_factor=1)\n",
    "template_acq_data.write('template.hs')\n",
    "# create listmode-to-sinograms converter object\n",
    "lm2sino = pet.ListmodeToSinograms()\n",
    "\n",
    "# set input, output and template files\n",
    "lm2sino.set_input(list_file)\n",
    "lm2sino.set_output_prefix(sino_file)\n",
    "lm2sino.set_template('template.hs')\n",
    "# set timing interval (in secs) since start of acquisition\n",
    "# (the listmode file provided is for 1 hour).\n",
    "# you can vary this to see the effect on noise. Increasing it will mean somewhat longer\n",
    "# processing time in the following steps (but not in the reconstruction).\n",
    "lm2sino.set_time_interval(0, 500)\n",
    "# set up the converter\n",
    "lm2sino.set_up()\n",
    "# create the prompts sinogram\n",
    "lm2sino.process()\n",
    "# get access to the sinograms\n",
    "# acq_data = lm2sino.get_output()\n",
    "acq_data = pet.AcquisitionData('sino_f1g1d0b0.hs')\n",
    "\n",
    "# use a slice number for display that is appropriate for the NEMA phantom\n",
    "z = 71\n",
    "\n",
    "# uncomment to show the acquisition data\n",
    "# show2D(acq_data, slice_list=[(0,0),(1,z)], title='500s', cmap='gray_r' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the randoms estimate\n",
    "# This will take a while\n",
    "rand = lm2sino.estimate_randoms()\n",
    "rand.write('sino_randoms_f1g1d0b0')\n",
    "\n",
    "# uncomment to show the randoms\n",
    "# show2D(rand, slice_list=[(0,0),(1,z)], title='randoms 500s', cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-hello",
   "metadata": {},
   "source": [
    "## OSEM reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquisition data stored in memory\n",
    "pet.AcquisitionData.set_storage_scheme('memory')\n",
    "pet.set_verbosity(0)\n",
    "\n",
    "# attenuation\n",
    "attns = pet.ImageData('mu_map.hv')\n",
    "asm_norm = pet.AcquisitionSensitivityModel('norm.n.hdr')\n",
    "\n",
    "# Setup image geometry\n",
    "image = acq_data.create_uniform_image(0., (127, 220, 220))\n",
    "image.initialise(dim=(127, 220, 220), vsize=(2.03125, 1.7080754, 1.7080754))\n",
    "\n",
    "def get_asm_attn(sino, attn, acq_model):\n",
    "    \"\"\"Get attn Attenuation Sensitivity Model from sino, attn image and acq model.\"\"\"\n",
    "    asm_attn = pet.AcquisitionSensitivityModel(attn, acq_model)\n",
    "    # temporary fix pending attenuation offset fix in STIR:\n",
    "    # converting attenuation into 'bin efficiency'\n",
    "    asm_attn.set_up(sino)\n",
    "    bin_eff = pet.AcquisitionData(sino)\n",
    "    bin_eff.fill(1.0)\n",
    "    asm_attn.unnormalise(bin_eff)\n",
    "    asm_attn = pet.AcquisitionSensitivityModel(bin_eff)\n",
    "    return asm_attn\n",
    "\n",
    "# set up the acquisition model\n",
    "if SIRF_HAS_Parallelproj:\n",
    "    # use a GPU implementation if available\n",
    "    am = pet.AcquisitionModelUsingParallelproj()\n",
    "else:\n",
    "    am = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "\n",
    "# ASM norm already there\n",
    "asm_attn = get_asm_attn(acq_data,attns,am)\n",
    "\n",
    "# Get ASM dependent on attn and/or norm\n",
    "asm = pet.AcquisitionSensitivityModel(asm_norm, asm_attn)\n",
    "am.set_acquisition_sensitivity(asm)\n",
    "am.set_background_term(rand)\n",
    "am.set_up(acq_data, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup OSEM\n",
    "obj_fun = pet.make_Poisson_loglikelihood(acq_data)\n",
    "obj_fun.set_acquisition_model(am)\n",
    "\n",
    "recon = pet.OSMAPOSLReconstructor()\n",
    "recon.set_objective_function(obj_fun)\n",
    "recon.set_num_subsets(7)\n",
    "recon.set_num_subiterations(58)\n",
    "recon.set_up(image)\n",
    "\n",
    "# set the initial image estimate\n",
    "recon.set_current_estimate(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run OSEM\n",
    "recon.process()\n",
    "osem_recon = recon.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-creativity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show OSEM recon\n",
    "# show2D(osem_recon.as_array()[72,:,:], cmap=\"inferno\", fix_range=(0,0.15), origin=\"upper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-caribbean",
   "metadata": {},
   "source": [
    "## Reconstruction with TV regularisation using PDHG and preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get linear acquisition model\n",
    "K = am.get_linear_acquisition_model()\n",
    "# K.img_templ = am.img_templ\n",
    "# K.acq_templ = am.acq_templ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-withdrawal",
   "metadata": {},
   "source": [
    "To accelerate the reconstruction, we use diagonal preconditioning to compute $\\sigma$ and $\\tau$ based on the operator K. See [here](https://ieeexplore.ieee.org/document/6126441) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_sigma = K.direct(K.domain_geometry().allocate(1.)).power(-1)\n",
    "tmp_tau   = K.adjoint(K.range_geometry().allocate(1.)).power(-1)\n",
    "\n",
    "tmp_tau_np = tmp_tau.as_array()\n",
    "tmp_tau_np[tmp_tau_np==np.inf] = 1e-5\n",
    "tau = tmp_tau*0.\n",
    "tau.fill(tmp_tau_np)\n",
    "\n",
    "tmp_sigma_np = tmp_sigma.as_array()\n",
    "tmp_sigma_np[tmp_sigma_np==np.inf] = 1e-5\n",
    "sigma = tmp_sigma*0.\n",
    "sigma.fill(tmp_sigma_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-cable",
   "metadata": {},
   "source": [
    "The implementation of `FGP_TV` does not accept $\\tau$ as a `numpy` array. Hence, we change its `proximal` method to a `precond_proximal` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precond_proximal(self,x,tau, out=None):\n",
    "        in_arr = np.asarray(x.as_array()/tau.as_array(), dtype=np.float32, order='C')      \n",
    "        res , info = regularisers.FGP_TV(\\\n",
    "              in_arr,\\\n",
    "              self.alpha,\\\n",
    "              self.max_iteration,\\\n",
    "              self.tolerance,\\\n",
    "              self.methodTV,\\\n",
    "              self.nonnegativity,\\\n",
    "              self.device)\n",
    "        if out is not None:\n",
    "            out.fill(res)\n",
    "        else:\n",
    "            out = x.copy()\n",
    "            out.fill(res)\n",
    "        out *= tau    \n",
    "        return out    \n",
    "    \n",
    "FGP_TV.proximal = precond_proximal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-discount",
   "metadata": {},
   "source": [
    "Next, we define the fidelity term **KullbackLeibler** based on the acqusition data and random events. For the regularisation term we use the **FGP_TV** function class from the [CCPi-RegTk](https://github.com/vais-ral/CCPi-Regularisation-Toolkit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 13.0\n",
    "F = KullbackLeibler(b = acq_data, eta = rand)\n",
    "G = alpha * FGP_TV(max_iteration=100, device='gpu' )\n",
    "max_iterations = 500 # Use 500 to match the results in the paper. \n",
    "\n",
    "# Setup and run PDHG\n",
    "pdhg = PDHG(f = F, g = G, operator=K, sigma = sigma, tau = tau,\n",
    "            max_iteration = max_iterations, update_objective_interval = 100, use_axpby=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-wings",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdhg.run(verbose = 2, print_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "ss = 72\n",
    "plt.imshow(osem_recon.as_array()[ss,:,:], cmap=\"inferno\", vmax = 0.15)\n",
    "plt.title(\"OSEM\")\n",
    "plt.plot((125,125),(0,219),'-r')\n",
    "plt.colorbar()\n",
    "# plt.savefig(\"osem_annot.png\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(pdhg.solution.as_array()[ss,:,:], cmap=\"inferno\", vmax = 0.15)\n",
    "plt.title(\"PDHG + TV\")\n",
    "plt.plot((125,125),(0,219),'-r')\n",
    "plt.colorbar()\n",
    "# plt.savefig(\"pdhgtv_annot.png\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(osem_recon.as_array()[72,:,125],label='OSEM')\n",
    "plt.plot(pdhg.solution.as_array()[72,:,125],label='PDHG TV')\n",
    "plt.legend()\n",
    "# plt.savefig('vertical_profile.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-fitness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
